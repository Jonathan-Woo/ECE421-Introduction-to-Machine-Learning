{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz9MhPEUMrkC"
      },
      "source": [
        "**Assignment**: Designing and Tuning a Convolutional Neural Network (CNN)\n",
        "\n",
        "**Assignment Description**: There are four parts to this assignment\n",
        "\n",
        "1.   Building a CNN\n",
        "2.   Training and Tuning a CNN\n",
        "3.   Trying Out a New Dataset\n",
        "4.   Open-Ended Exploration\n",
        "\n",
        "You will be largely guided through the first two parts. The third and fourth part are discussion based questions. \n",
        "\n",
        "**Before the experiment, make sure that you have GPU enabled. This setting can be found under *Tools --> Settings***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHvVs2GqXxNF"
      },
      "source": [
        "#Install Objax\n",
        "!pip --quiet install  objax\n",
        "import objax"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqQf8f2RBDcx"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import jax.numpy as jn\n",
        "import random \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_7vcWRFO39r"
      },
      "source": [
        "##**Part 1. Building a CNN** \n",
        "\n",
        "Before we build our CNN model, let's first import a dataset. For our experiment, we load the CIFAR10 dataset from Tensorflow's dataset repository. The CIFAR10 dataset consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n",
        "\n",
        "After loading the dataset, we split the dataset into training, validation and test set. The dataset is originally stored as 50,000 training examples and 10,000 test examples. Instead, we will combine them together and make our own split.\n",
        "\n",
        "Do not change split ratio for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5VQDzs1XodT"
      },
      "source": [
        "#.load_data() by default returns a split between training and test set. \n",
        "# We then adjust the training set into a format that can be accepted by our CNN\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train.transpose(0, 3, 1, 2) / 255.0\n",
        "Y_train = Y_train.flatten()\n",
        "X_test = X_test.transpose(0, 3, 1, 2) / 255.0\n",
        "Y_test = Y_test.flatten()\n",
        "\n",
        "np.random.seed(1)\n",
        "# To create a validation set, we first concate the original splitted dataset into a single dataset \n",
        "# then randomly shuffle the images and labels in the same way (seed = 1)\n",
        "X_data = np.concatenate([X_train, X_test], axis = 0)\n",
        "Y_data = np.concatenate([Y_train, Y_test], axis = 0)\n",
        "\n",
        "N = np.arange(len(X_data))\n",
        "np.random.shuffle(N)\n",
        "X_data = X_data[N]\n",
        "Y_data = Y_data[N]\n",
        "\n",
        "#Next, we partition the randomly shuffled dataset into training, validation and testset according a ratio\n",
        "train_ratio = 0.80\n",
        "valid_ratio = 0.1\n",
        "n_train = int(len(X_data) * train_ratio)\n",
        "n_valid = int(len(X_data) * valid_ratio)\n",
        "\n",
        "X_train, X_valid, X_test = X_data[:n_train], X_data[n_train:n_train+n_valid], X_data[n_train+n_valid:]\n",
        "Y_train, Y_valid, Y_test = Y_data[:n_train], Y_data[n_train:n_train+n_valid], Y_data[n_train+n_valid:]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.(1 point) Your data has been split into training, validation and test set. Examine the ratio of the split and number of examples in each set. Suppose you were to train on batches of 32 examples each. That is, in each step of gradient descent, you randomly select 32 examples from the training set, compute your average loss on these examples, and then compute the gradient of this average loss with respect to the model parameters.\n",
        "\n",
        "How many iterations will it take to go through the entire training set given the number of training examples yielded by the data split? How many iterations are there in 30 epochs? Recall that one epoch is the number of iterations needed to train over the entire dataset."
      ],
      "metadata": {
        "id": "_9FJvsEAi45p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsMS56ocjS1k",
        "outputId": "0922403b-0680-420c-d1e1-33fa53418f44"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 3, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With 48000 training examples, at batch of 32 examples each, each epoch will require 48000/32 = 1500 iterations to go through the entire training set.\n",
        "\n",
        "In 30 epochs, there are 30 * 1500 = 45000 total iterations."
      ],
      "metadata": {
        "id": "7mTYkvQljYNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.(1 point) Explain in a short paragraph what is the difference between the training and validation set.\n",
        "\n",
        "The training set is used to learn parameters of the model through numerical methods including gradient descent. \n",
        "\n",
        "The validatino set is used to learn hyperparameters of the model typically by training multiple models on the training set with varying hyperparameter values and testing on the validation set. Then, the hyperparameters corresponding to the lowest validation loss are chosen."
      ],
      "metadata": {
        "id": "zlGRu2u3kXMv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szDmexFGT7Qs"
      },
      "source": [
        "\n",
        "Next we will construct a **Base Model**, which in our case is a small CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eeh6jvfBV4p"
      },
      "source": [
        "class ConvNet(objax.Module):\n",
        "  def __init__(self, number_of_channels = 3, number_of_classes = 10):\n",
        "    self.conv_1 = objax.nn.Sequential([objax.nn.Conv2D(number_of_channels, 16, 2), objax.functional.relu])\n",
        "    self.conv_2 = objax.nn.Sequential([objax.nn.Conv2D(16, 32, 2), objax.functional.relu])\n",
        "    self.linear = objax.nn.Linear(32, number_of_classes)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = objax.functional.max_pool_2d(self.conv_1(x), 2, 2)\n",
        "    x = self.conv_2(x)\n",
        "  \n",
        "    x = x.mean((2,3)) #<--- global average pooling \n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "#The following line creates the CNN\n",
        "model = ConvNet()\n",
        "#You can examine the architecture of our CNN by calling model.vars()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crz2dQZBds89"
      },
      "source": [
        "Before we train our conv net, let's try to better understand concepts of convolution filter and linear layer. In the following, you will take the first very image of the training set, create a simple convolution routine, and show that our own routine matches what Objax returns. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epa7ETf6XddH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9bf4378d-9b83-44f5-ffaf-67aaf445c63a"
      },
      "source": [
        "#Let's plot the first image in the training set.\n",
        "plt.imshow(X_train[0].transpose(1,2,0))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f34f47069d0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQjS06vgXZ7r"
      },
      "source": [
        "Next, we will pass our image through Objax's convolution routine. Carefully examine the following code and try to understand the dimension of the filter weights and the output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFBbJHBpXXUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcd56fc-28f0-417d-96fa-f93075ee169e"
      },
      "source": [
        "# We append the first image with a batch size of 1 so it can be fed into a convolution layer\n",
        "my_image = np.expand_dims(X_train[0], 0)\n",
        "\n",
        "#Consider a very simple CNN filter with stride = 1 and no padding ('VALID').\n",
        "Conv2d = objax.nn.Conv2D(nin = 3, nout = 2, k = 1, strides = 1, padding = 'VALID', use_bias = False)\n",
        "\n",
        "filter_weights = Conv2d.w.value #This is the initial weight of the filter, which we gradually update when training, we ignore bias for now\n",
        "\n",
        "print(\"Filter weights:\", filter_weights)\n",
        "print(\"Conv output:\", Conv2d(my_image))\n",
        "print(\"Conv output shape:\", np.shape(Conv2d(my_image)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filter weights: [[[[-0.0836635   0.29303992]\n",
            "   [-0.6150833  -0.30144012]\n",
            "   [-0.7410647  -0.3469479 ]]]]\n",
            "Conv output: [[[[-0.15979855 -0.15415223 -0.13430713 ... -1.131044   -1.1131169\n",
            "    -1.1040704 ]\n",
            "   [-0.21626174 -0.18561804 -0.19077031 ... -1.1492877  -1.1445751\n",
            "    -1.1389288 ]\n",
            "   [-0.22190806 -0.18803014 -0.21900192 ... -1.1428583  -1.1436299\n",
            "    -1.1383154 ]\n",
            "   ...\n",
            "   [-0.24843808 -0.23714544 -0.23714544 ... -0.31025857 -0.3159049\n",
            "    -0.33284384]\n",
            "   [-0.20891383 -0.1976212  -0.1976212  ... -0.34413648 -0.33849016\n",
            "    -0.33849016]\n",
            "   [-0.18632856 -0.18068224 -0.18632856 ... -0.42318496 -0.41753864\n",
            "    -0.4005997 ]]\n",
            "\n",
            "  [[-0.04659335 -0.04519983 -0.03965868 ... -0.38578457 -0.3812471\n",
            "    -0.37831452]\n",
            "   [-0.06052857 -0.05237884 -0.0535939  ... -0.37775952 -0.38081717\n",
            "    -0.37942368]\n",
            "   [-0.06192209 -0.05356096 -0.06056151 ... -0.35802466 -0.36495265\n",
            "    -0.3662144 ]\n",
            "   ...\n",
            "   [-0.06131497 -0.05852792 -0.05852792 ... -0.05848081 -0.05987434\n",
            "    -0.0640549 ]\n",
            "   [-0.05156032 -0.04877327 -0.04877327 ... -0.06684195 -0.06544843\n",
            "    -0.06544843]\n",
            "   [-0.04598623 -0.0445927  -0.04598623 ... -0.08635126 -0.08495774\n",
            "    -0.08077718]]]]\n",
            "Conv output shape: (1, 2, 32, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsDg8yateSuH"
      },
      "source": [
        "**In the cells below, you will create your own convolution routine that takes in the image and the initial weights used by Objax's own convolution routine (Conv2d.w.value) and show that your convolution routine returns the same value than Objax's.**\n",
        "\n",
        "A simple implementation only requires 4 FOR loops. You may wish to draw inspiration from https://objax.readthedocs.io/en/latest/objax/nn.html?highlight=objax.nn.Conv2D#objax.nn.Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5B6K9gyXTAx"
      },
      "source": [
        "#Solution to the above problem\n",
        "\n",
        "def my_conv_net(my_image, initial_filter_weights):\n",
        "  N, C_in, H_in, W_in = my_image.shape\n",
        "  k, _, _, C_out = initial_filter_weights.shape\n",
        "  H_out = H_in - k + 1\n",
        "  W_out = W_in - k + 1\n",
        "  my_conv_output = jn.zeros((N, C_out, H_out, W_out))\n",
        "  total = 0\n",
        "  for n in range(N):\n",
        "    for c in range(C_out):\n",
        "      for h in range(H_out):\n",
        "        for w in range(W_out):\n",
        "          my_conv_output = my_conv_output.at[n, c, h, w].set(np.sum(my_image[n,:,h:h+k, w:w+k]*initial_filter_weights[:,:,:,c].transpose(2,0,1)))\n",
        "  return my_conv_output"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test function\n",
        "my_conv_output = my_conv_net(my_image, filter_weights)"
      ],
      "metadata": {
        "id": "mo8iRY4uVXlW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Conv output:\", my_conv_output)\n",
        "print('Conv output shape:', my_conv_output.shape)\n",
        "print('Conv output absolute mean difference', np.mean(np.absolute((my_conv_output - Conv2d(my_image)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSHH2BvoWDN4",
        "outputId": "193a5928-c439-46e1-d27a-51b363203aca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv output: [[[[-0.15979853 -0.15415221 -0.13430712 ... -1.131044   -1.113117\n",
            "    -1.1040704 ]\n",
            "   [-0.21626174 -0.18561804 -0.19077033 ... -1.1492877  -1.1445751\n",
            "    -1.1389288 ]\n",
            "   [-0.22190806 -0.18803014 -0.21900192 ... -1.1428583  -1.1436299\n",
            "    -1.1383154 ]\n",
            "   ...\n",
            "   [-0.24843806 -0.23714542 -0.23714542 ... -0.31025857 -0.31590486\n",
            "    -0.33284384]\n",
            "   [-0.20891383 -0.1976212  -0.1976212  ... -0.34413648 -0.33849016\n",
            "    -0.33849016]\n",
            "   [-0.18632856 -0.18068224 -0.18632856 ... -0.42318496 -0.41753864\n",
            "    -0.4005997 ]]\n",
            "\n",
            "  [[-0.04659335 -0.04519983 -0.03965868 ... -0.38578457 -0.3812471\n",
            "    -0.37831455]\n",
            "   [-0.06052857 -0.05237884 -0.0535939  ... -0.37775952 -0.38081717\n",
            "    -0.37942368]\n",
            "   [-0.06192209 -0.05356096 -0.06056151 ... -0.35802466 -0.36495268\n",
            "    -0.3662144 ]\n",
            "   ...\n",
            "   [-0.06131497 -0.05852792 -0.05852792 ... -0.05848081 -0.05987434\n",
            "    -0.0640549 ]\n",
            "   [-0.05156032 -0.04877327 -0.04877327 ... -0.06684195 -0.06544843\n",
            "    -0.06544843]\n",
            "   [-0.04598623 -0.0445927  -0.04598623 ... -0.08635126 -0.08495774\n",
            "    -0.08077718]]]]\n",
            "Conv output shape: (1, 2, 32, 32)\n",
            "Conv output absolute mean difference 5.7536766e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since my convolution output differs from Conv2d by ~5.21e-9 and that it has the same output shape, I can confirm that it performs the same function as Objax's."
      ],
      "metadata": {
        "id": "e41kY2j_bfJH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9dbovOwiVDE"
      },
      "source": [
        "The outputs of last convolution layer is typically rearranged so it can be fed into a linear layer. Check that calling .mean((2,3)) rearranges the output of your convolution routine by examining the shape of the output. (Not graded) Think about alternative ways of rearranging the output from the convolution layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hngIUNXIMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a70d24-1b9f-4886-f01d-315424a7dbe5"
      },
      "source": [
        "#Check that .mean((2,3)) rearranges your image\n",
        "my_conv_output.mean((2,3))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-0.39710045, -0.07775426]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTWfvL0mis3D"
      },
      "source": [
        "Take your rearranged output and feed it into a linear layer of appropriate size. Here is an example:\n",
        "\n",
        "```\n",
        "Linear_Layer = objax.nn.Linear(N, 1)\n",
        "Y = Linear_Layer(X)\n",
        "```\n",
        "Next, extract the weights and bias of the linear layer using \n",
        "```\n",
        "Linear_Layer.w.value\n",
        "Linear_Layer.b.value\n",
        "```\n",
        "**Using these values, write one line of code that manually implements the linear layer. Show that it provides the same value as Objax's own linear layer.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq-TkFpgXDC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1069b5e8-d0dd-411c-9299-c48e913211c2"
      },
      "source": [
        "X = my_conv_output.mean((2,3))\n",
        "N = X.shape[1]\n",
        "Linear_Layer = objax.nn.Linear(N,1)\n",
        "Y = Linear_Layer(X)\n",
        "\n",
        "w = Linear_Layer.w.value\n",
        "b = Linear_Layer.b.value\n",
        "\n",
        "#ONE LINE HERE\n",
        "my_Y = np.matmul(X,w)+b\n",
        "\n",
        "#Verify that values are same\n",
        "print(Y, my_Y)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.49124828]] [[-0.49124828]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Y value is equal to the Objax output."
      ],
      "metadata": {
        "id": "9VgMCYEBe6l5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QQXl3d2kZn"
      },
      "source": [
        "You have now completed Part 1 of the assignment. Good job!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqaH75UUaSE"
      },
      "source": [
        "##**Part 2. Training and Tuning a CNN**\n",
        "\n",
        "The following starter code trains the neural network in Part 1. However, the optimizer and batch sampling routine are left for you to implement. Complete the lines that says #PUT YOUR CODE HERE#\n",
        "\n",
        "Afterwards, train the model, and observe the training/validation loss and accuracy plots. You should observe that the validation accuracy is low and stagnates after a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBcHWoCl0URZ"
      },
      "source": [
        "#Define loss function as averaged value of of cross entropies\n",
        "def loss_function(x, labels):\n",
        "    logit = model(x)\n",
        "    return objax.functional.loss.cross_entropy_logits_sparse(logit, labels).mean()\n",
        "\n",
        "#Define a prediction function\n",
        "predict = objax.Jit(lambda x: objax.functional.softmax(model(x)), model.vars()) \n",
        "\n",
        "#Create an object that can be used to calculate the gradient and value of loss_function\n",
        "gv= objax.GradValues(loss_function, model.vars())\n",
        "\n",
        "#Create an object that can be used to provide trainable variables in the model\n",
        "tv = objax.ModuleList(objax.TrainRef(x) for x in model.vars().subset(objax.TrainVar))\n",
        "\n",
        "#Training routine\n",
        "def train_op(x, y, learning_rate):\n",
        "    lr = learning_rate\n",
        "    gradient, loss_value = gv(x, y)   # calculate gradient and loss value \"backprop\"\n",
        "    #next we update the trainable parameter using SGD and similar procedure\n",
        "    for grad, params in zip(gradient, tv.vars()):\n",
        "      params.assign(params - grad*lr)\n",
        "    return loss_value                      # return loss value\n",
        "\n",
        "#make train_op (much) faster using JIT compilation\n",
        "train_op = objax.Jit(train_op, gv.vars() + tv.vars())"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGPpVTfG0Ug1"
      },
      "source": [
        "def train(EPOCHS = 50, BATCH = 32, LEARNING_RATE = 9e-4):\n",
        "  avg_train_loss_epoch = []\n",
        "  avg_val_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_acc_epoch = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      avg_train_loss = 0 # (averaged) training loss per batch\n",
        "      avg_val_loss =  0  # (averaged) validation loss per batch\n",
        "      train_acc = 0      # training accuracy per batch\n",
        "      val_acc = 0        # validation accuracy per batch\n",
        "\n",
        "      # shuffle the examples prior to training to remove correlation \n",
        "      train_indices = np.arange(len(X_train)) \n",
        "      np.random.shuffle(train_indices)\n",
        "      for it in range(0, X_train.shape[0], BATCH):\n",
        "          batch = train_indices[it:it+BATCH]\n",
        "          avg_train_loss += float(train_op(X_train[batch], Y_train[batch], LEARNING_RATE)[0]) * len(batch)\n",
        "          train_prediction = predict(X_train[batch]).argmax(1)\n",
        "          train_acc += (np.array(train_prediction).flatten() == Y_train[batch]).sum()\n",
        "      train_acc_epoch.append(train_acc/X_train.shape[0])\n",
        "      avg_train_loss_epoch.append(avg_train_loss/X_train.shape[0])\n",
        "\n",
        "      # run validation\n",
        "      val_indices = np.arange(len(X_valid)) \n",
        "      np.random.shuffle(val_indices)    \n",
        "      for it in range(0, X_valid.shape[0], BATCH):\n",
        "          batch = val_indices[it:it+BATCH]\n",
        "          avg_val_loss += float(loss_function(X_valid[batch], Y_valid[batch])) * len(batch)\n",
        "          val_prediction = predict(X_valid[batch]).argmax(1)\n",
        "          val_acc += (np.array(val_prediction).flatten() == Y_valid[batch]).sum()\n",
        "      val_acc_epoch.append(val_acc/X_valid.shape[0])\n",
        "      avg_val_loss_epoch.append(avg_val_loss/X_valid.shape[0])\n",
        "\n",
        "      print('Epoch %04d  Training Loss %.2f Validation Loss %.2f Training Accuracy %.2f Validation Accuracy %.2f' % (epoch + 1, avg_train_loss/X_train.shape[0], avg_val_loss/X_valid.shape[0], 100*train_acc/X_train.shape[0], 100*val_acc/X_valid.shape[0]))\n",
        "  \n",
        "  #Plot training loss\n",
        "  plt.title(\"Train vs Validation Loss\")\n",
        "  plt.plot(avg_train_loss_epoch, label=\"Train\")\n",
        "  plt.plot(avg_val_loss_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Train vs Validation Accuracy\")\n",
        "  plt.plot(train_acc_epoch, label=\"Train\")\n",
        "  plt.plot(val_acc_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YqWtV5VYW45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "877b52fb-b0ed-4865-84af-4fb333627668"
      },
      "source": [
        "train()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0001  Training Loss 2.30 Validation Loss 2.29 Training Accuracy 12.47 Validation Accuracy 15.65\n",
            "Epoch 0002  Training Loss 2.29 Validation Loss 2.29 Training Accuracy 14.25 Validation Accuracy 14.07\n",
            "Epoch 0003  Training Loss 2.29 Validation Loss 2.28 Training Accuracy 13.84 Validation Accuracy 14.20\n",
            "Epoch 0004  Training Loss 2.28 Validation Loss 2.28 Training Accuracy 14.19 Validation Accuracy 15.65\n",
            "Epoch 0005  Training Loss 2.28 Validation Loss 2.27 Training Accuracy 15.84 Validation Accuracy 16.27\n",
            "Epoch 0006  Training Loss 2.27 Validation Loss 2.27 Training Accuracy 16.29 Validation Accuracy 16.78\n",
            "Epoch 0007  Training Loss 2.26 Validation Loss 2.26 Training Accuracy 17.12 Validation Accuracy 17.57\n",
            "Epoch 0008  Training Loss 2.25 Validation Loss 2.25 Training Accuracy 17.49 Validation Accuracy 18.50\n",
            "Epoch 0009  Training Loss 2.24 Validation Loss 2.24 Training Accuracy 18.37 Validation Accuracy 18.83\n",
            "Epoch 0010  Training Loss 2.23 Validation Loss 2.22 Training Accuracy 18.80 Validation Accuracy 19.05\n",
            "Epoch 0011  Training Loss 2.22 Validation Loss 2.21 Training Accuracy 19.29 Validation Accuracy 19.12\n",
            "Epoch 0012  Training Loss 2.21 Validation Loss 2.20 Training Accuracy 19.29 Validation Accuracy 19.53\n",
            "Epoch 0013  Training Loss 2.19 Validation Loss 2.18 Training Accuracy 19.41 Validation Accuracy 20.08\n",
            "Epoch 0014  Training Loss 2.18 Validation Loss 2.17 Training Accuracy 20.00 Validation Accuracy 20.20\n",
            "Epoch 0015  Training Loss 2.16 Validation Loss 2.15 Training Accuracy 20.30 Validation Accuracy 20.47\n",
            "Epoch 0016  Training Loss 2.15 Validation Loss 2.14 Training Accuracy 20.61 Validation Accuracy 20.52\n",
            "Epoch 0017  Training Loss 2.14 Validation Loss 2.13 Training Accuracy 21.06 Validation Accuracy 20.83\n",
            "Epoch 0018  Training Loss 2.13 Validation Loss 2.12 Training Accuracy 21.04 Validation Accuracy 21.73\n",
            "Epoch 0019  Training Loss 2.12 Validation Loss 2.12 Training Accuracy 21.40 Validation Accuracy 21.68\n",
            "Epoch 0020  Training Loss 2.12 Validation Loss 2.11 Training Accuracy 22.01 Validation Accuracy 21.77\n",
            "Epoch 0021  Training Loss 2.11 Validation Loss 2.10 Training Accuracy 22.07 Validation Accuracy 22.13\n",
            "Epoch 0022  Training Loss 2.11 Validation Loss 2.10 Training Accuracy 22.39 Validation Accuracy 22.40\n",
            "Epoch 0023  Training Loss 2.10 Validation Loss 2.10 Training Accuracy 22.49 Validation Accuracy 22.55\n",
            "Epoch 0024  Training Loss 2.10 Validation Loss 2.09 Training Accuracy 22.85 Validation Accuracy 22.88\n",
            "Epoch 0025  Training Loss 2.10 Validation Loss 2.09 Training Accuracy 22.91 Validation Accuracy 23.38\n",
            "Epoch 0026  Training Loss 2.09 Validation Loss 2.09 Training Accuracy 23.31 Validation Accuracy 23.57\n",
            "Epoch 0027  Training Loss 2.09 Validation Loss 2.09 Training Accuracy 23.26 Validation Accuracy 23.17\n",
            "Epoch 0028  Training Loss 2.09 Validation Loss 2.08 Training Accuracy 23.58 Validation Accuracy 23.15\n",
            "Epoch 0029  Training Loss 2.09 Validation Loss 2.08 Training Accuracy 23.56 Validation Accuracy 24.02\n",
            "Epoch 0030  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 23.65 Validation Accuracy 23.87\n",
            "Epoch 0031  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 23.89 Validation Accuracy 24.12\n",
            "Epoch 0032  Training Loss 2.08 Validation Loss 2.07 Training Accuracy 24.09 Validation Accuracy 24.47\n",
            "Epoch 0033  Training Loss 2.08 Validation Loss 2.07 Training Accuracy 24.07 Validation Accuracy 24.67\n",
            "Epoch 0034  Training Loss 2.08 Validation Loss 2.07 Training Accuracy 24.21 Validation Accuracy 24.48\n",
            "Epoch 0035  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.29 Validation Accuracy 24.80\n",
            "Epoch 0036  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.37 Validation Accuracy 24.62\n",
            "Epoch 0037  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.39 Validation Accuracy 24.97\n",
            "Epoch 0038  Training Loss 2.07 Validation Loss 2.06 Training Accuracy 24.81 Validation Accuracy 24.97\n",
            "Epoch 0039  Training Loss 2.07 Validation Loss 2.06 Training Accuracy 24.75 Validation Accuracy 24.98\n",
            "Epoch 0040  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 24.93 Validation Accuracy 25.20\n",
            "Epoch 0041  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 25.17 Validation Accuracy 24.95\n",
            "Epoch 0042  Training Loss 2.06 Validation Loss 2.05 Training Accuracy 25.24 Validation Accuracy 25.05\n",
            "Epoch 0043  Training Loss 2.06 Validation Loss 2.05 Training Accuracy 25.28 Validation Accuracy 25.33\n",
            "Epoch 0044  Training Loss 2.06 Validation Loss 2.05 Training Accuracy 25.49 Validation Accuracy 25.45\n",
            "Epoch 0045  Training Loss 2.05 Validation Loss 2.05 Training Accuracy 25.51 Validation Accuracy 25.85\n",
            "Epoch 0046  Training Loss 2.05 Validation Loss 2.05 Training Accuracy 25.77 Validation Accuracy 25.63\n",
            "Epoch 0047  Training Loss 2.05 Validation Loss 2.04 Training Accuracy 25.68 Validation Accuracy 25.85\n",
            "Epoch 0048  Training Loss 2.05 Validation Loss 2.04 Training Accuracy 25.82 Validation Accuracy 25.87\n",
            "Epoch 0049  Training Loss 2.04 Validation Loss 2.04 Training Accuracy 25.89 Validation Accuracy 26.03\n",
            "Epoch 0050  Training Loss 2.04 Validation Loss 2.04 Training Accuracy 26.14 Validation Accuracy 26.45\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hluN6UIbNyj7"
      },
      "source": [
        "Follow the assignment handout for questions to be answered in this part of the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.(1 point) In one sentence, define the meaning of a hyperparameter. Explain in a short paragraph why it is important not to evaluate the accuracy on the test set until all hyperparameters have been tuned.\n",
        "\n",
        "Hyperparameters are parameters that cannot be learned by gradient descent on the training set. Instead, they are intialized/chosen when the model is generated and affect the models behaviour and performance. \n",
        "\n",
        "The accuracy on the test set represents generalizability of the model. Thus, it should only be evaluated once with our final model. After training parameters on the training set and tuning hyperparameters on the validation set, their values are set. Finally, test set is input to the model only once. "
      ],
      "metadata": {
        "id": "ink_dtA-lCRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.(2 points) Select 4 hyperparameters associated with your network, one of the hyperparameter must involve your CNN architecture, and come up with two different sets of hyperparameters.\n",
        "\n",
        "I selected the learning rate, batch size, number of convolutional layers, and the activation function for each convolutional layer.\n",
        "\n",
        "H1 = {0.001, 32, 2, ReLU}\n",
        "H2 = {0.0001, 16, 3, SELU}"
      ],
      "metadata": {
        "id": "mhADP6GrmpPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.(3 points) Create two additional networks M1, M2, each with the set of hyperparameter H1, H2 that you have selected above. Train each model. Report the best validation accuracy as well as the corresponding epoch for which this occurs for the Base Model and your two additional models."
      ],
      "metadata": {
        "id": "KntOt3Tmk9Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create M1\n",
        "class ConvNet(objax.Module):\n",
        "  def __init__(self, number_of_channels = 3, number_of_classes = 10):\n",
        "    #RELU ACTIVATION\n",
        "    #2 CONV LAYERS\n",
        "    self.conv_1 = objax.nn.Sequential([objax.nn.Conv2D(number_of_channels, 16, 2), objax.functional.relu])\n",
        "    self.conv_2 = objax.nn.Sequential([objax.nn.Conv2D(16, 32, 2), objax.functional.relu])\n",
        "    self.linear = objax.nn.Linear(32, number_of_classes)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = objax.functional.max_pool_2d(self.conv_1(x), 2, 2)\n",
        "    x = self.conv_2(x)\n",
        "  \n",
        "    x = x.mean((2,3)) #<--- global average pooling \n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "#The following line creates the CNN\n",
        "model = ConvNet()"
      ],
      "metadata": {
        "id": "ZW5uYnHnlhGt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function as averaged value of of cross entropies\n",
        "def loss_function(x, labels):\n",
        "    logit = model(x)\n",
        "    return objax.functional.loss.cross_entropy_logits_sparse(logit, labels).mean()\n",
        "\n",
        "#Define a prediction function\n",
        "predict = objax.Jit(lambda x: objax.functional.softmax(model(x)), model.vars()) \n",
        "\n",
        "#Create an object that can be used to calculate the gradient and value of loss_function\n",
        "gv= objax.GradValues(loss_function, model.vars())\n",
        "\n",
        "#Create an object that can be used to provide trainable variables in the model\n",
        "tv = objax.ModuleList(objax.TrainRef(x) for x in model.vars().subset(objax.TrainVar))\n",
        "\n",
        "#Training routine\n",
        "def train_op(x, y, learning_rate):\n",
        "    lr = learning_rate\n",
        "    gradient, loss_value = gv(x, y)   # calculate gradient and loss value \"backprop\"\n",
        "    #next we update the trainable parameter using SGD and similar procedure\n",
        "    for grad, params in zip(gradient, tv.vars()):\n",
        "      params.assign(params - grad*lr)\n",
        "    return loss_value                      # return loss value\n",
        "\n",
        "#make train_op (much) faster using JIT compilation\n",
        "train_op = objax.Jit(train_op, gv.vars() + tv.vars())"
      ],
      "metadata": {
        "id": "IPppEu0Uq9kK"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_M1(EPOCHS = 50, BATCH = 32, LEARNING_RATE = 0.001):   # 0.001 LR, SIZE 32 BATCH\n",
        "  avg_train_loss_epoch = []\n",
        "  avg_val_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_acc_epoch = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      avg_train_loss = 0 # (averaged) training loss per batch\n",
        "      avg_val_loss =  0  # (averaged) validation loss per batch\n",
        "      train_acc = 0      # training accuracy per batch\n",
        "      val_acc = 0        # validation accuracy per batch\n",
        "\n",
        "      # shuffle the examples prior to training to remove correlation \n",
        "      train_indices = np.arange(len(X_train)) \n",
        "      np.random.shuffle(train_indices)\n",
        "      for it in range(0, X_train.shape[0], BATCH):\n",
        "          batch = train_indices[it:it+BATCH]\n",
        "          avg_train_loss += float(train_op(X_train[batch], Y_train[batch], LEARNING_RATE)[0]) * len(batch)\n",
        "          train_prediction = predict(X_train[batch]).argmax(1)\n",
        "          train_acc += (np.array(train_prediction).flatten() == Y_train[batch]).sum()\n",
        "      train_acc_epoch.append(train_acc/X_train.shape[0])\n",
        "      avg_train_loss_epoch.append(avg_train_loss/X_train.shape[0])\n",
        "\n",
        "      # run validation\n",
        "      val_indices = np.arange(len(X_valid)) \n",
        "      np.random.shuffle(val_indices)    \n",
        "      for it in range(0, X_valid.shape[0], BATCH):\n",
        "          batch = val_indices[it:it+BATCH]\n",
        "          avg_val_loss += float(loss_function(X_valid[batch], Y_valid[batch])) * len(batch)\n",
        "          val_prediction = predict(X_valid[batch]).argmax(1)\n",
        "          val_acc += (np.array(val_prediction).flatten() == Y_valid[batch]).sum()\n",
        "      val_acc_epoch.append(val_acc/X_valid.shape[0])\n",
        "      avg_val_loss_epoch.append(avg_val_loss/X_valid.shape[0])\n",
        "\n",
        "      print('Epoch %04d  Training Loss %.2f Validation Loss %.2f Training Accuracy %.2f Validation Accuracy %.2f' % (epoch + 1, avg_train_loss/X_train.shape[0], avg_val_loss/X_valid.shape[0], 100*train_acc/X_train.shape[0], 100*val_acc/X_valid.shape[0]))\n",
        "  \n",
        "  #Plot training loss\n",
        "  plt.title(\"Train vs Validation Loss for M1\")\n",
        "  plt.plot(avg_train_loss_epoch, label=\"Train\")\n",
        "  plt.plot(avg_val_loss_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Train vs Validation Accuracy for M1\")\n",
        "  plt.plot(train_acc_epoch, label=\"Train\")\n",
        "  plt.plot(val_acc_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "A5ABbhvJox8Z"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_M1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eaTb4OulL8P",
        "outputId": "0bc423b2-2650-44e4-8379-78e7401dedc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0001  Training Loss 2.31 Validation Loss 2.30 Training Accuracy 11.88 Validation Accuracy 13.63\n",
            "Epoch 0002  Training Loss 2.29 Validation Loss 2.29 Training Accuracy 13.70 Validation Accuracy 13.65\n",
            "Epoch 0003  Training Loss 2.29 Validation Loss 2.28 Training Accuracy 14.37 Validation Accuracy 14.60\n",
            "Epoch 0004  Training Loss 2.28 Validation Loss 2.27 Training Accuracy 15.19 Validation Accuracy 15.62\n",
            "Epoch 0005  Training Loss 2.27 Validation Loss 2.27 Training Accuracy 15.90 Validation Accuracy 16.62\n",
            "Epoch 0006  Training Loss 2.26 Validation Loss 2.26 Training Accuracy 16.34 Validation Accuracy 18.08\n",
            "Epoch 0007  Training Loss 2.25 Validation Loss 2.24 Training Accuracy 17.68 Validation Accuracy 18.97\n",
            "Epoch 0008  Training Loss 2.24 Validation Loss 2.23 Training Accuracy 18.34 Validation Accuracy 17.58\n",
            "Epoch 0009  Training Loss 2.23 Validation Loss 2.22 Training Accuracy 18.47 Validation Accuracy 18.00\n",
            "Epoch 0010  Training Loss 2.21 Validation Loss 2.20 Training Accuracy 18.73 Validation Accuracy 18.32\n",
            "Epoch 0011  Training Loss 2.20 Validation Loss 2.19 Training Accuracy 19.29 Validation Accuracy 19.73\n",
            "Epoch 0012  Training Loss 2.18 Validation Loss 2.17 Training Accuracy 19.63 Validation Accuracy 20.38\n",
            "Epoch 0013  Training Loss 2.17 Validation Loss 2.16 Training Accuracy 20.22 Validation Accuracy 20.03\n",
            "Epoch 0014  Training Loss 2.16 Validation Loss 2.15 Training Accuracy 20.52 Validation Accuracy 20.83\n",
            "Epoch 0015  Training Loss 2.14 Validation Loss 2.14 Training Accuracy 21.29 Validation Accuracy 20.37\n",
            "Epoch 0016  Training Loss 2.14 Validation Loss 2.13 Training Accuracy 21.22 Validation Accuracy 21.98\n",
            "Epoch 0017  Training Loss 2.13 Validation Loss 2.12 Training Accuracy 21.93 Validation Accuracy 21.43\n",
            "Epoch 0018  Training Loss 2.12 Validation Loss 2.12 Training Accuracy 22.04 Validation Accuracy 20.83\n",
            "Epoch 0019  Training Loss 2.12 Validation Loss 2.11 Training Accuracy 22.11 Validation Accuracy 22.33\n",
            "Epoch 0020  Training Loss 2.11 Validation Loss 2.11 Training Accuracy 22.48 Validation Accuracy 22.52\n",
            "Epoch 0021  Training Loss 2.11 Validation Loss 2.10 Training Accuracy 22.79 Validation Accuracy 21.92\n",
            "Epoch 0022  Training Loss 2.10 Validation Loss 2.10 Training Accuracy 22.72 Validation Accuracy 21.73\n",
            "Epoch 0023  Training Loss 2.10 Validation Loss 2.10 Training Accuracy 22.60 Validation Accuracy 22.58\n",
            "Epoch 0024  Training Loss 2.10 Validation Loss 2.09 Training Accuracy 23.06 Validation Accuracy 23.58\n",
            "Epoch 0025  Training Loss 2.09 Validation Loss 2.09 Training Accuracy 23.36 Validation Accuracy 23.32\n",
            "Epoch 0026  Training Loss 2.09 Validation Loss 2.09 Training Accuracy 23.29 Validation Accuracy 23.67\n",
            "Epoch 0027  Training Loss 2.09 Validation Loss 2.09 Training Accuracy 23.62 Validation Accuracy 23.35\n",
            "Epoch 0028  Training Loss 2.09 Validation Loss 2.08 Training Accuracy 23.50 Validation Accuracy 22.88\n",
            "Epoch 0029  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 23.64 Validation Accuracy 23.97\n",
            "Epoch 0030  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 23.95 Validation Accuracy 23.70\n",
            "Epoch 0031  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 23.76 Validation Accuracy 24.07\n",
            "Epoch 0032  Training Loss 2.08 Validation Loss 2.08 Training Accuracy 24.18 Validation Accuracy 23.87\n",
            "Epoch 0033  Training Loss 2.08 Validation Loss 2.07 Training Accuracy 24.18 Validation Accuracy 24.15\n",
            "Epoch 0034  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.34 Validation Accuracy 23.47\n",
            "Epoch 0035  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.29 Validation Accuracy 23.80\n",
            "Epoch 0036  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.46 Validation Accuracy 24.65\n",
            "Epoch 0037  Training Loss 2.07 Validation Loss 2.07 Training Accuracy 24.61 Validation Accuracy 24.30\n",
            "Epoch 0038  Training Loss 2.07 Validation Loss 2.06 Training Accuracy 24.75 Validation Accuracy 24.40\n",
            "Epoch 0039  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 24.66 Validation Accuracy 25.13\n",
            "Epoch 0040  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 25.04 Validation Accuracy 25.18\n",
            "Epoch 0041  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 25.05 Validation Accuracy 24.45\n",
            "Epoch 0042  Training Loss 2.06 Validation Loss 2.06 Training Accuracy 24.98 Validation Accuracy 24.52\n",
            "Epoch 0043  Training Loss 2.06 Validation Loss 2.05 Training Accuracy 25.05 Validation Accuracy 25.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create M2\n",
        "class ConvNet(objax.Module):\n",
        "  def __init__(self, number_of_channels = 3, number_of_classes = 10):\n",
        "    #SELU ACTIVATION\n",
        "    self.conv_1 = objax.nn.Sequential([objax.nn.Conv2D(number_of_channels, 16, 2), objax.functional.selu])\n",
        "    self.conv_2 = objax.nn.Sequential([objax.nn.Conv2D(16, 32, 2), objax.functional.selu])\n",
        "    #3 CONV LAYERS\n",
        "    self.conv_3 = objax.nn.Sequential([objax.nn.Conv2D(32, 32, 2), objax.functional.selu])\n",
        "    self.linear = objax.nn.Linear(32, number_of_classes)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = objax.functional.max_pool_2d(self.conv_1(x), 2, 2)\n",
        "    x = self.conv_2(x)\n",
        "  \n",
        "    x = x.mean((2,3)) #<--- global average pooling \n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "#The following line creates the CNN\n",
        "model = ConvNet()"
      ],
      "metadata": {
        "id": "76HjonkYoM6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function as averaged value of of cross entropies\n",
        "def loss_function(x, labels):\n",
        "    logit = model(x)\n",
        "    return objax.functional.loss.cross_entropy_logits_sparse(logit, labels).mean()\n",
        "\n",
        "#Define a prediction function\n",
        "predict = objax.Jit(lambda x: objax.functional.softmax(model(x)), model.vars()) \n",
        "\n",
        "#Create an object that can be used to calculate the gradient and value of loss_function\n",
        "gv= objax.GradValues(loss_function, model.vars())\n",
        "\n",
        "#Create an object that can be used to provide trainable variables in the model\n",
        "tv = objax.ModuleList(objax.TrainRef(x) for x in model.vars().subset(objax.TrainVar))\n",
        "\n",
        "#Training routine\n",
        "def train_op(x, y, learning_rate):\n",
        "    lr = learning_rate\n",
        "    gradient, loss_value = gv(x, y)   # calculate gradient and loss value \"backprop\"\n",
        "    #next we update the trainable parameter using SGD and similar procedure\n",
        "    for grad, params in zip(gradient, tv.vars()):\n",
        "      params.assign(params - grad*lr)\n",
        "    return loss_value                      # return loss value\n",
        "\n",
        "#make train_op (much) faster using JIT compilation\n",
        "train_op = objax.Jit(train_op, gv.vars() + tv.vars())"
      ],
      "metadata": {
        "id": "GjBeUcPArQ4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_M2(EPOCHS = 50, BATCH = 16, LEARNING_RATE = 0.0001):  #0.0001 LR, SIZE 16 BATCH\n",
        "  avg_train_loss_epoch = []\n",
        "  avg_val_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_acc_epoch = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      avg_train_loss = 0 # (averaged) training loss per batch\n",
        "      avg_val_loss =  0  # (averaged) validation loss per batch\n",
        "      train_acc = 0      # training accuracy per batch\n",
        "      val_acc = 0        # validation accuracy per batch\n",
        "\n",
        "      # shuffle the examples prior to training to remove correlation \n",
        "      train_indices = np.arange(len(X_train)) \n",
        "      np.random.shuffle(train_indices)\n",
        "      for it in range(0, X_train.shape[0], BATCH):\n",
        "          batch = train_indices[it:it+BATCH]\n",
        "          avg_train_loss += float(train_op(X_train[batch], Y_train[batch], LEARNING_RATE)[0]) * len(batch)\n",
        "          train_prediction = predict(X_train[batch]).argmax(1)\n",
        "          train_acc += (np.array(train_prediction).flatten() == Y_train[batch]).sum()\n",
        "      train_acc_epoch.append(train_acc/X_train.shape[0])\n",
        "      avg_train_loss_epoch.append(avg_train_loss/X_train.shape[0])\n",
        "\n",
        "      # run validation\n",
        "      val_indices = np.arange(len(X_valid)) \n",
        "      np.random.shuffle(val_indices)    \n",
        "      for it in range(0, X_valid.shape[0], BATCH):\n",
        "          batch = val_indices[it:it+BATCH]\n",
        "          avg_val_loss += float(loss_function(X_valid[batch], Y_valid[batch])) * len(batch)\n",
        "          val_prediction = predict(X_valid[batch]).argmax(1)\n",
        "          val_acc += (np.array(val_prediction).flatten() == Y_valid[batch]).sum()\n",
        "      val_acc_epoch.append(val_acc/X_valid.shape[0])\n",
        "      avg_val_loss_epoch.append(avg_val_loss/X_valid.shape[0])\n",
        "\n",
        "      print('Epoch %04d  Training Loss %.2f Validation Loss %.2f Training Accuracy %.2f Validation Accuracy %.2f' % (epoch + 1, avg_train_loss/X_train.shape[0], avg_val_loss/X_valid.shape[0], 100*train_acc/X_train.shape[0], 100*val_acc/X_valid.shape[0]))\n",
        "  \n",
        "  #Plot training loss\n",
        "  plt.title(\"Train vs Validation Loss for M2\")\n",
        "  plt.plot(avg_train_loss_epoch, label=\"Train\")\n",
        "  plt.plot(avg_val_loss_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Train vs Validation Accuracy for M2\")\n",
        "  plt.plot(train_acc_epoch, label=\"Train\")\n",
        "  plt.plot(val_acc_epoch, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "DrTy1i4XoM6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_M2()"
      ],
      "metadata": {
        "id": "3-aY3V7koM6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8SwTIjc3pThT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOXmJiGZF78"
      },
      "source": [
        "You have now completed Part 2 of the assignment. Good job!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cno9fjO1o2Jq"
      },
      "source": [
        "##**Part 3. Trying Out a New Dataset**\n",
        "\n",
        "See the handout for instructions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eye-uBnQWgc8"
      },
      "source": [
        "##**Problem 4. Open-Ended Exploration**\n",
        "\n",
        "See the handout for instructions."
      ]
    }
  ]
}